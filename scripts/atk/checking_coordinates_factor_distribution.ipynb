{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gs\n",
    "from matplotlib.colors import LogNorm\n",
    "import scipy as sp\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from igraph import Graph\n",
    "import ipdb\n",
    "\n",
    "rd = np.random\n",
    "dst = sp.spatial.distance\n",
    "non_zero_force = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_G(file_path):\n",
    "    if file_path[-1] == \"f\":\n",
    "        g = nx.read_gpickle(file_path)\n",
    "        \n",
    "    if file_path[-1] == \"t\":\n",
    "        g = Graph.Read_Pickle(file_path)\n",
    "        g.to_undirected()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placing Initial Condictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nx = charge_G('../../data/net/net_nx_cart_cust.gexf')\n",
    "g_nx = max(nx.connected_component_subgraphs(g_nx), key=len)\n",
    "g_ig = charge_G('../../data/net/net_ig_cart_cust.dat')\n",
    "g_ig = g_ig.clusters().giant()\n",
    "\n",
    "alphabet = list(map(chr, range(97, 123)))\n",
    "\n",
    "beta = 3\n",
    "alpha = 2\n",
    "L = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Position Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nodes = np.array(list(g_nx.nodes))\n",
    "G_pos = np.array(\n",
    "    [list(x) for x in nx.get_node_attributes(g_nx, 'n_pos').values()])\n",
    "\n",
    "#--------------------------Get m attribute-----------------------------------\n",
    "\n",
    "D_norm_m = G_pos.copy()[:, 0]\n",
    "P_norm_m = beta*np.exp(-D_norm_m/(L*alpha))\n",
    "k_norm_m = dict(zip(G_nodes, D_norm_m))\n",
    "nx.set_node_attributes(g_nx, name='k_norm_m', values=k_norm_m)\n",
    "\n",
    "D_inv_m = np.repeat(D_norm_m.max(), G_nodes.size) - D_norm_m\n",
    "P_inv_m = beta*np.exp(-D_inv_m/(L*alpha))\n",
    "k_inv_m = dict(zip(G_nodes, D_inv_m))\n",
    "nx.set_node_attributes(g_nx, name='k_inv_m', values=k_inv_m)\n",
    "\n",
    "\n",
    "p_norm_m = [x/D_norm_m.sum() for x in D_norm_m]\n",
    "p_inv_m = [x/D_inv_m.sum() for x in D_inv_m]\n",
    "\n",
    "\n",
    "#--------------------------Get d attribute-----------------------------------\n",
    "\n",
    "D_norm_d = G_pos.copy()[:, 1]\n",
    "P_norm_d = beta*np.exp(-D_norm_d/(L*alpha))\n",
    "k_norm_d = dict(zip(G_nodes, D_norm_d))\n",
    "nx.set_node_attributes(g_nx, name='k_norm_d', values=k_norm_d)\n",
    "\n",
    "D_inv_d = np.repeat(D_norm_d.max(), G_nodes.size) - D_norm_d\n",
    "P_inv_d = beta*np.exp(-D_inv_d/(L*alpha))\n",
    "k_inv_d = dict(zip(G_nodes, D_inv_d))\n",
    "nx.set_node_attributes(g_nx, name='k_inv_d', values=k_inv_d)\n",
    "\n",
    "p_norm_d = [x/D_norm_d.sum() for x in D_norm_d]\n",
    "p_inv_d = [x/D_inv_d.sum() for x in D_inv_d]\n",
    "\n",
    "\n",
    "#--------------------------Get a attribute-----------------------------------\n",
    "wish = 90\n",
    "#-----------a0---------------------------------------------------------------\n",
    "D_norm_a = G_pos.copy()[:, 2]\n",
    "P_norm_a = ((D_norm_a - wish)**2)**0.5\n",
    "# P_norm_a = beta*np.exp(-D_norm_a/(L*alpha))\n",
    "k_norm_a = dict(zip(G_nodes, P_norm_a))\n",
    "nx.set_node_attributes(g_nx, name='k_norm_a', values=k_norm_a)\n",
    "\n",
    "D_inv_a = D_norm_a - np.repeat(D_norm_a.max(), G_nodes.size)\n",
    "P_inv_a = ((D_inv_a - wish)**2)**0.5\n",
    "# P_inv_a = beta*np.exp(-D_inv_a/(L*alpha))\n",
    "k_inv_a = dict(zip(G_nodes, P_inv_a))\n",
    "nx.set_node_attributes(g_nx, name='k_inv_a', values=k_inv_a)\n",
    "\n",
    "p_norm_a = [x/P_norm_a.sum() for x in P_norm_a]\n",
    "p_inv_a = [x/P_inv_a.sum() for x in P_inv_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nodes = np.array(list(g_nx.nodes))\n",
    "G_pos = np.array(\n",
    "    [list(x) for x in nx.get_node_attributes(g_nx, 'n_pos').values()])\n",
    "\n",
    "#--------------------------Get a attribute-----------------------------------\n",
    "wish = 180\n",
    "#-----------a0---------------------------------------------------------------\n",
    "D_norm_a = G_pos.copy()[:, 2]\n",
    "P_norm_a = ((wish - D_norm_a)**2)**0.5 + 1e-50\n",
    "# P_norm_a = beta*np.exp(-D_norm_a/(L*alpha))\n",
    "# k_norm_a = dict(zip(G_nodes, P_norm_a))\n",
    "# nx.set_node_attributes(g_nx, name='k_norm_a', values=k_norm_a)\n",
    "\n",
    "D_inv_a = D_norm_a - np.repeat(D_norm_a.max()+1, G_nodes.size)\n",
    "P_inv_a = ((wish - D_inv_a)**2)**0.5 + 1e-50\n",
    "# P_inv_a = beta*np.exp(-D_inv_a/(L*alpha))\n",
    "#k_inv_a = dict(zip(G_nodes, P_inv_a))\n",
    "# nx.set_node_attributes(g_nx, name='k_inv_a', values=k_inv_a)\n",
    "\n",
    "# p_norm_a = [x/P_norm_a.sum() for x in P_norm_a]\n",
    "# p_inv_a = [x/P_inv_a.sum() for x in P_inv_a]\n",
    "\n",
    "P_pref_a = np.where(P_norm_a < P_inv_a, P_norm_a, P_inv_a)\n",
    "p_pref_a = [x/P_pref_a.sum() for x in P_pref_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(D_norm_a, [100*i for i in P], 'o', markersize=.2)\n",
    "plt.plot(D_norm_a, [100*i for i in p_pref_a], 'o', markersize=.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.081083418558743e-56"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(p_pref_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001643246796209289"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pref_a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Position Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True)\n",
    "\n",
    "#ax1.scatter(D_norm_m, [100*i for i in p_norm_d])\n",
    "#ax2.scatter(D_norm_m, [100*i for i in  p_inv_d])\n",
    "\n",
    "axs[0,0].scatter(D_norm_m, [100*i for i in p_norm_m])\n",
    "axs[1,0].scatter(D_norm_m, [100*i for i in  p_inv_m])\n",
    "\n",
    "axs[0,0].get_shared_x_axes().join(axs[0,0], axs[1,0])\n",
    "axs[0,0].set_xticklabels([])\n",
    "\n",
    "axs[0,0].set_ylabel(\"normal prob.\\n\")\n",
    "axs[1,0].set_ylabel(\"inverse prob.\")\n",
    "axs[1,0].set_xlabel(\"Distance\")\n",
    "axs[0,0].set_title(\"midl\\n(a)\")\n",
    "axs[1,0].set_title(\"(d)\")\n",
    "\n",
    "\n",
    "\n",
    "axs[0,1].scatter(D_norm_d, [100*i for i in p_norm_d])\n",
    "axs[1,1].scatter(D_norm_d, [100*i for i in  p_inv_d])\n",
    "\n",
    "axs[0,1].get_shared_x_axes().join(axs[0,1], axs[1,1])\n",
    "axs[0,1].set_xticklabels([])\n",
    "\n",
    "axs[1,1].set_xlabel(\"Distance\")\n",
    "axs[0,1].set_title(\"dist\\n(b)\")\n",
    "axs[1,1].set_title(\"(e)\")\n",
    "\n",
    "\n",
    "\n",
    "axs[0,2].scatter(D_norm_a, [100*i for i in p_norm_a])\n",
    "axs[1,2].scatter(D_norm_a, [100*i for i in  p_inv_a])\n",
    "\n",
    "axs[0,2].get_shared_x_axes().join(axs[0,2], axs[1,2])\n",
    "axs[0,2].set_xticklabels([])\n",
    "\n",
    "axs[1,2].set_xlabel(\"Distance\")\n",
    "axs[0,2].set_title(\"angl\\n(c)\")\n",
    "axs[1,2].set_title(\"(f)\")\n",
    "\n",
    "\n",
    "#ax1.set_ylim(-0.05, 0.02)\n",
    "#ax2.set_ylim(-0.05, 0.02)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Network Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------NetworkX Methods----------------------------\n",
    "G_degree = np.array(list(g_nx.degree))[:, 1]+non_zero_force\n",
    "p_degree = np.array([x/np.sum(G_degree) for x in G_degree])\n",
    "\n",
    "G_cluster = np.array(\n",
    "    np.array(list(nx.clustering(g_nx).values())))+non_zero_force\n",
    "p_cluster = np.array([x/np.sum(G_cluster) for x in G_cluster])\n",
    "\n",
    "#-------------iGraph Methods----------------------------\n",
    "G_betweenness = np.nan_to_num(\n",
    "    np.array(g_ig.betweenness()))+non_zero_force\n",
    "p_betweenness = np.array([x/np.sum(G_betweenness) for x in G_betweenness])\n",
    "\n",
    "G_closeness = np.nan_to_num(\n",
    "    np.array(g_ig.closeness()))+non_zero_force\n",
    "p_closeness = np.array([x/np.sum(G_closeness) for x in G_closeness])\n",
    "\n",
    "G_eigenvector = np.nan_to_num(np.array(\n",
    "    g_ig.eigenvector_centrality()))+non_zero_force\n",
    "p_eigenvector = np.array([x/np.sum(G_eigenvector) for x in G_eigenvector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Position Attributes Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=5, ncols=3, constrained_layout=True, figsize=[10,10])\n",
    "\n",
    "axs[0,0].scatter(D_norm_m, G_degree, s=2, alpha=0.1)\n",
    "axs[0,1].scatter(D_norm_d, G_degree, s=2, alpha=0.1)\n",
    "axs[0,2].scatter(D_norm_a, G_degree, s=2, alpha=0.1)\n",
    "\n",
    "axs[1,0].scatter(D_norm_m, G_cluster, s=2, alpha=0.1)\n",
    "axs[1,1].scatter(D_norm_d, G_cluster, s=2, alpha=0.1)\n",
    "axs[1,2].scatter(D_norm_a, G_cluster, s=2, alpha=0.1)\n",
    "\n",
    "axs[2,0].plot(D_norm_m, G_betweenness, 'o', markersize=2, alpha=0.1)\n",
    "axs[2,1].plot(D_norm_d, G_betweenness, 'o', markersize=2, alpha=0.1)\n",
    "axs[2,2].plot(D_norm_a, G_betweenness, 'o', markersize=2, alpha=0.1)\n",
    "axs[2,0].set_yscale('log')\n",
    "axs[2,1].set_yscale('log')\n",
    "axs[2,2].set_yscale('log')\n",
    "\n",
    "axs[3,0].scatter(D_norm_m, G_closeness, s=2, alpha=0.1)\n",
    "axs[3,1].scatter(D_norm_d, G_closeness, s=2, alpha=0.1)\n",
    "axs[3,2].scatter(D_norm_a, G_closeness, s=2, alpha=0.1)\n",
    "\n",
    "axs[4,0].plot(D_norm_m, G_eigenvector, 'o', markersize=2, alpha=0.1)\n",
    "axs[4,1].plot(D_norm_d, G_eigenvector, 'o', markersize=2, alpha=0.1)\n",
    "axs[4,2].plot(D_norm_a, G_eigenvector, 'o', markersize=2, alpha=0.1)\n",
    "axs[4,0].set_yscale('log')\n",
    "axs[4,1].set_yscale('log')\n",
    "axs[4,2].set_yscale('log')\n",
    "\n",
    "axs[0,0].get_shared_x_axes().join(axs[0,0], axs[1,0])\n",
    "axs[1,0].get_shared_x_axes().join(axs[1,0], axs[2,0])\n",
    "axs[2,0].get_shared_x_axes().join(axs[2,0], axs[3,0])\n",
    "axs[3,0].get_shared_x_axes().join(axs[3,0], axs[4,0])\n",
    "\n",
    "axs[0,1].get_shared_x_axes().join(axs[0,1], axs[1,1])\n",
    "axs[1,1].get_shared_x_axes().join(axs[1,1], axs[2,1])\n",
    "axs[2,1].get_shared_x_axes().join(axs[2,1], axs[3,1])\n",
    "axs[3,1].get_shared_x_axes().join(axs[3,1], axs[4,1])\n",
    "\n",
    "axs[0,2].get_shared_x_axes().join(axs[0,2], axs[1,2])\n",
    "axs[1,2].get_shared_x_axes().join(axs[1,2], axs[2,2])\n",
    "axs[2,2].get_shared_x_axes().join(axs[2,2], axs[3,2])\n",
    "axs[3,2].get_shared_x_axes().join(axs[3,2], axs[4,2])\n",
    "\n",
    "axs[0,0].set_xticklabels([])\n",
    "axs[1,0].set_xticklabels([])\n",
    "axs[2,0].set_xticklabels([])\n",
    "axs[3,0].set_xticklabels([])\n",
    "\n",
    "axs[0,1].set_xticklabels([])\n",
    "axs[1,1].set_xticklabels([])\n",
    "axs[2,1].set_xticklabels([])\n",
    "axs[3,1].set_xticklabels([])\n",
    "\n",
    "axs[0,2].set_xticklabels([])\n",
    "axs[1,2].set_xticklabels([])\n",
    "axs[2,2].set_xticklabels([])\n",
    "axs[3,2].set_xticklabels([])\n",
    "\n",
    "axs[0,1].set_yticklabels([])\n",
    "axs[1,1].set_yticklabels([])\n",
    "axs[2,1].set_yticklabels([])\n",
    "axs[3,1].set_yticklabels([])\n",
    "axs[4,1].set_yticklabels([])\n",
    "\n",
    "axs[0,2].set_yticklabels([])\n",
    "axs[1,2].set_yticklabels([])\n",
    "axs[2,2].set_yticklabels([])\n",
    "axs[3,2].set_yticklabels([])\n",
    "axs[4,2].set_yticklabels([])\n",
    "\n",
    "axs[0,0].set_ylabel(\"Degree\")\n",
    "axs[1,0].set_ylabel(\"Cluster\")\n",
    "axs[2,0].set_ylabel(\"Betweenness\")\n",
    "axs[3,0].set_ylabel(\"Closeness\")\n",
    "axs[4,0].set_ylabel(\"Eigenvector\")\n",
    "\n",
    "# axs[0,0].set_ylabel(\"Deg\")\n",
    "# axs[1,0].set_ylabel(\"Clu\")\n",
    "# axs[2,0].set_ylabel(\"Bet\")\n",
    "# axs[3,0].set_ylabel(\"Clo\")\n",
    "# axs[4,0].set_ylabel(\"Eig\")\n",
    "\n",
    "axs[4,0].set_xlabel(\"Distance\")\n",
    "axs[4,1].set_xlabel(\"Distance\")\n",
    "axs[4,2].set_xlabel(\"Distance\")\n",
    "\n",
    "mark = 0\n",
    "for r, linha in enumerate(axs):\n",
    "    for c, graph in enumerate(linha):\n",
    "        # if r == 0:\n",
    "        #     if c == 0:\n",
    "        #         axs[r, c].set_title('middline\\n({})'.format(alphabet[mark]))\n",
    "        #     elif c == 1:\n",
    "        #         axs[r, c].set_title('distance\\n({})'.format(alphabet[mark]))\n",
    "        #     elif c == 2:\n",
    "        #         axs[r, c].set_title('angle\\n({})'.format(alphabet[mark]))\n",
    "        # else:\n",
    "        #     axs[r, c].set_title('({})'.format(alphabet[mark]))\n",
    "        axs[r, c].set_title('({})'.format(alphabet[mark]))\n",
    "        mark += 1\n",
    "\n",
    "plt.savefig('../../results/properties-distribution/net_distr_lab_noname.jpg')\n",
    "plt.savefig('../../results/properties-distribution/net_distr_lab_noname.eps')\n",
    "plt.savefig('../../results/properties-distribution/net_distr_lab_noname.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Position Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True, figsize=[10,10])\n",
    "\n",
    "axs[0,0].hist(G_degree)\n",
    "axs[0,1].hist(G_cluster)\n",
    "axs[0,2].hist(G_betweenness)\n",
    "axs[1,0].hist(G_closeness)\n",
    "axs[1,1].plot(G_eigenvector)\n",
    "\n",
    "\n",
    "axs[0,0].set_title(\"Degree\")\n",
    "axs[0,1].set_title(\"Cluster\")\n",
    "axs[0,2].set_title(\"Betweenness\")\n",
    "axs[1,0].set_title(\"Closeness\")\n",
    "axs[1,1].set_title(\"Eigenvector\")\n",
    "\n",
    "\n",
    "axs[0,0].set_xlabel(\"(a)\")\n",
    "axs[0,1].set_xlabel(\"(b)\")\n",
    "axs[0,2].set_xlabel(\"(c)\")\n",
    "axs[1,0].set_xlabel(\"(d)\")\n",
    "axs[1,1].set_xlabel(\"(e)\")\n",
    "\n",
    "mark = 0\n",
    "# for r, linha in enumerate(axs):\n",
    "#     for c, graph in enumerate(linha):\n",
    "#         axs[r, c].set_xlabel('({})'.format(alphabet[mark]))\n",
    "#         mark += 1\n",
    "\n",
    "plt.savefig('../../results/properties-distribution/net_distr_hist.jpg')\n",
    "plt.savefig('../../results/properties-distribution/net_distr_hist.eps')\n",
    "plt.savefig('../../results/properties-distribution/net_distr_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Beak Betweenness Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positions\n",
    "v_bin = 25\n",
    "h_bin = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for n, node in enumerate(g_nx.nodes(data=True)):\n",
    "    pos_x = node[1]['c_pos'][1]\n",
    "    # pos_y = node[1]['c_pos'][2]\n",
    "    pos_z = node[1]['c_pos'][0]\n",
    "    bet = G_betweenness[n]\n",
    "    pos2d = (pos_x, pos_z)\n",
    "    \n",
    "    if pos2d in data.keys():\n",
    "        data[pos2d].append(bet)\n",
    "    else:    \n",
    "        data[pos2d] = [bet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_max = 0\n",
    "for i in data.values():\n",
    "    if len(i) > tmp_max:\n",
    "        # print(len(i))\n",
    "        tmp_max = len(i)\n",
    "\n",
    "for i in data.values():\n",
    "    rep = tmp_max - len(i)\n",
    "    for r in range(rep):\n",
    "        i.append(np.mean(i))\n",
    "        \n",
    "betweenness = np.array(list(data.values()))\n",
    "position = np.array(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_mean = np.zeros(position.max(axis=0)+(1,1))\n",
    "bet_max = np.zeros(position.max(axis=0)+(1,1))\n",
    "\n",
    "for b, i in enumerate(position):\n",
    "    bet_mean[i[0], i[1]] = betweenness.mean(axis=1)[b]\n",
    "    bet_max[i[0], i[1]] = betweenness.max(axis=1)[b]\n",
    "    \n",
    "bet_mean = np.flip(bet_mean, axis=0)\n",
    "bet_max = np.flip(bet_max, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_mean += 1e-5\n",
    "bet_max += 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(matrix, r_conv, c_conv, method='max'):\n",
    "    r_pass = int(matrix.shape[0]/r_conv)\n",
    "    c_pass = int(matrix.shape[1]/c_conv)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferno\n",
    "# seismic\n",
    "# gnuplot2\n",
    "\n",
    "plt.pcolormesh(bet_max, cmap='gnuplot2', norm=LogNorm(vmin=bet_max.min(), vmax=bet_max.max()))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
